from pymongo import MongoClient
import json
import datetime
import sys

# Class implemented to do mongodb-related functions
# Still contains useless functions that will be removed
class database_handler(object): 
	# Initialization of database connection
	def __init__(self, ip, port):
		self.mongoclient = MongoClient(ip, port)

		# MIGHT NEED TO BE REFRESHED?
		self.category_db = self.mongoclient.category

	# Returns all data in a collection 
	def print_data(self, collection):
		return [items for items in collection.find({})]

	# Clears an entire collection and prints the ammount of objects removed
	def clear_collection(self, collection):
		cnt = 0

		for item in collection.find({}):
			collection.remove(item)
			cnt += 1

		if cnt > 0:
			print "Cleared %d elements in the collection" % cnt
		else:
			print "Nothing to clear."

	# Removes a single datapoint based on the datareference. 
	def remove_one(self, collection, id):
		data = collection.find_one({'_id': id})

		if data is not None:
			collection.remove({'_id': id})

	def get_available_category_collections(self):
		category_collection = self.category_db.collection_names(include_system_collections=False)
		return category_collection

	# Adds data to a category and returns the ID generated by MongoDB
	def add_new_category_data(self, database, category, name, cur_time, ip="", url="", filehash=""):
		collection = database[category]
		
		if collection.find({"name": name}).count() > 0:
			category_data = collection.find_one({"name": name})
			# Might want to append ObjectID instead of IP? idk :)
			# Append appropriate data to list
			if ip and ip not in category_data["ips"]:	
				category_data["ips"].append(ip)
			if url and url not in category_data["urls"]:
				category_data["urls"].append(url)
			if filehash and filehash not in category_data["filehash"]:	
				category_data["filehash"].append(filehash)

			category_data["modifieddate"] = cur_time
			collection.save(category_data)
			return category_data["_id"]
		else:
			# To create a new object
			category_data = {
					"name": name,
					"ips": [],
					"urls": [],
					"filehash": [],
					"addeddate": cur_time,
					"modifieddate": cur_time
			}

			# Add check for multiple urls and hashes? idk
			if ip:
				category_data["ips"].append(ip)
			if url:
				category_data["urls"].append(url)
			if filehash:
				category_data["filehash"].append(filehash)

			return_id = collection.insert_one(category_data).inserted_id
			return return_id

	# Adds an IP. Should be made generic to contain other sources like URL and filehash
	def add_new_ip(self, database, ip_collection, category_db, ip, category="", name=""):
		object_exists = False
		# Creates category data.
		category_id = ""
		cur_time = datetime.datetime.now()

		if category and name:
		    category_id = self.add_new_category_data(category_db, category, name, cur_time, ip=ip) 


		# Item already exists.
		if ip_collection.find({"ip": ip}).count() > 0:
			tmp_data = ip_collection.find_one({"ip": ip})
			# Verify data in containers

			# Might be slow!
			category_exists = False
			for item in tmp_data["containers"]:
				if item["name"] == name and item["category"] == category:
					category_exists = True
					break

			# append
			if not category_exists:
				tmp_data["containers"].append({"name": name, \
					"category": category, "mongo_id": category_id, "addeddate": cur_time})
				tmp_data["modifieddate"] = cur_time
				ip_collection.save(tmp_data)

			# Return otherwise - might want to modify date of category if category/name exists?

		# New item
		else:
			# Base information to add to a colleciton
			tmp_data = {
				"ip": "%s" % ip,
				"containers": [],
				"addeddate": "%s" % cur_time,
				"modifieddate": "%s" % cur_time
			}

			if category_id:
				tmp_data["containers"].append({"name": name, \
					"category": category, "mongo_id": category_id, "addeddate": cur_time})

			return ip_collection.insert_one(tmp_data).inserted_id

	def find_category_object(self, collection, id):
		data = collection.find_one({"_id": id})
		return data

	# Finds a single p in a collection - make generic
	def find_ip_object(self, collection, ip):
            return collection.find_one({"ip": ip})

	# Made to test listsa - Needs to contain category and stuff
	def get_data(self):
		return open("blocklist.php", "r").readlines()

	def generate_test_data(self):
		ips = []
		ip = "192.168.0."
		for i in range(0, 254):
			ips.append(ip+str(i))

		return ips

	# Test function to test mongodb connection functionality	
	def test_func(self):
		db = self.mongoclient.ip
		category_db = self.mongoclient.category

		#testdata = self.generate_test_data()
		testdata = self.generate_test_data()
		category = "c2"
		name = "zeus2"

		#self.clear_collection(db.ips)

		cnt = 0
		# Generate other data first to append to the IP-range
		for ip in testdata:
			#ip = ip[:-1]
			data = self.add_new_ip(db, db.ips, category_db, ip, \
			category=category, name=name)

			if data:
				cnt += 1

		if cnt > 0:
			print "Added %d elements to %s" % (cnt, "ips")
		else:
			print "All data already in database."


		# Categories in both DBs printed
		"""
		ip_collection = db.collection_names(include_system_collections=False)
		category_collection = category_db.collection_names(include_system_collections=False)
		for collect in ip_collection:
			print collect
		for collect in category_collection:
			print collect
		"""

		exit()
		# Attempt updating an item
		#post = db.ips.find_one({"ip": "101.200.81.187"}) 
			
		if post is not None:
			id = post["_id"]
			post["ip"] = "1.2.3.4"
			post["modifieddate"] = "\"%s\"" % datetime.datetime.now()
			db.ips.save(post)

			#print db.ips.find_one({"_id": id})
	def clear_all_databases(self):
		print "Here?"
		data = self.mongoclient.database_names()
		for items in data:
			self.mongoclient.drop_database(self.mongoclient[items])	
			print "Dropped %s" % items


# TEEEEST :D
if __name__ == "__main__":
	#app.run(debug=True)
	mongodbserver = '127.0.0.1'
	mongodbport = 27017
	print "Connecting to mongodb at %s:%d" % (mongodbserver, mongodbport)

	client = database_handler(mongodbserver, mongodbport)
	try:
		if sys.argv[1] == "clear":
			client.clear_all_databases()
			exit()
	except IndexError:
		client.test_func()
		exit()

	client.test_func()

